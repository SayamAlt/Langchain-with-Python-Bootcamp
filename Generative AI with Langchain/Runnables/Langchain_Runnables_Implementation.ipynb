{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod # ABC = Abstract Base Class and abstractmethod = Abstract Method\n",
        "import random"
      ],
      "metadata": {
        "id": "A8na_tE5ftJU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Runnable(ABC):\n",
        "\n",
        "  @abstractmethod\n",
        "  def invoke(input_data):\n",
        "    pass"
      ],
      "metadata": {
        "id": "ZOsIB8zOfYyM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeLLM(Runnable):\n",
        "\n",
        "  def __init__(self):\n",
        "    print('LLM Created')\n",
        "\n",
        "  def predict(self, prompt):\n",
        "    responses = [\n",
        "        'Delhi is the capital of India.',\n",
        "        'IPL is a cricket league.',\n",
        "        'AI stands for Artificial Intelligence.'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(responses)}\n",
        "\n",
        "  def invoke(self, prompt):\n",
        "    responses = [\n",
        "        'Delhi is the capital of India.',\n",
        "        'IPL is a cricket league.',\n",
        "        'AI stands for Artificial Intelligence.'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(responses)}"
      ],
      "metadata": {
        "id": "f8YXOcNOgED-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakePromptTemplate(Runnable):\n",
        "\n",
        "  def __init__(self, template, input_variables):\n",
        "    self.template = template\n",
        "    self.input_variables = input_variables\n",
        "\n",
        "  def format(self, input_dict):\n",
        "    return self.template.format(**input_dict)\n",
        "\n",
        "  def invoke(self, input_dict):\n",
        "    return self.template.format(**input_dict)"
      ],
      "metadata": {
        "id": "_0mQ5lRfgG-K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeStrOutputParser(Runnable):\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def invoke(self, input_data):\n",
        "    return input_data['response']"
      ],
      "metadata": {
        "id": "VGBcIDUpiwlB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunnableConnector(Runnable):\n",
        "\n",
        "  def __init__(self, runnables):\n",
        "    self.runnables = runnables\n",
        "\n",
        "  def invoke(self, input_data):\n",
        "\n",
        "    for runnable in self.runnables:\n",
        "      input_data = runnable.invoke(input_data)\n",
        "\n",
        "    return input_data"
      ],
      "metadata": {
        "id": "A5H6mbAPgIvA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = FakePromptTemplate(\n",
        "    template='Write a {length} poem about {topic}',\n",
        "    input_variables=['length','topic']\n",
        ")\n",
        "\n",
        "prompt = template.format({'length': 'short', 'topic': 'crystals'})"
      ],
      "metadata": {
        "id": "ghCH-QlIh2O7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = FakeLLM()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQIyAWygiSRv",
        "outputId": "8da02969-c23d-44c8-c8b3-b22f2eb3688e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = FakeStrOutputParser()"
      ],
      "metadata": {
        "id": "j9C_zyjFi8Ks"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnableConnector([template,llm,parser])"
      ],
      "metadata": {
        "id": "tLv7kPYghawE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'length': 'long', 'topic': 'Queensland'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qzmBTXgwib1u",
        "outputId": "520d4970-1195-4454-fa95-0b5927f3cf35"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Delhi is the capital of India.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template1 = FakePromptTemplate(\n",
        "    template='Write a joke about {topic}',\n",
        "    input_variables=['topic']\n",
        ")"
      ],
      "metadata": {
        "id": "29fFRgSUj77W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template2 = FakePromptTemplate(\n",
        "    template='Summarize the following joke: {response}',\n",
        "    input_variables=['response']\n",
        ")"
      ],
      "metadata": {
        "id": "7UAL0zNMj727"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = FakeLLM()\n",
        "parser = FakeStrOutputParser()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFoBJItRkXwn",
        "outputId": "ab282ac8-144e-4d21-80ca-7f45955b3137"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = RunnableConnector([template1,llm])\n",
        "chain2 = RunnableConnector([template2,llm,parser])"
      ],
      "metadata": {
        "id": "sZzQgXKikVuz"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chain1.invoke({'topic': 'AI'})"
      ],
      "metadata": {
        "id": "gvMtkVzZkkit"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chain2.invoke({'joke': 'This is a joke'})"
      ],
      "metadata": {
        "id": "caep5h2bkqZU"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = RunnableConnector([chain1,chain2])"
      ],
      "metadata": {
        "id": "4_sFAHkVkwa5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain.invoke({'topic': 'cricket'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lfc7jk3Vk6G_",
        "outputId": "75030eb0-b7a2-442b-a506-074e0c589cda"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI stands for Artificial Intelligence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}